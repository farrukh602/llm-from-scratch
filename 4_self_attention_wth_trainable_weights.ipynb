{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c1277a-d12a-4180-8968-bb34b3c94f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a4825-5d6f-4426-ba92-cb3d70858988",
   "metadata": {},
   "source": [
    "### Implementing self-attention with trainable weights\n",
    "This self-attention mechanism is also called scaled dot product attention. We want to compute context vectors\n",
    "as weighted sums over the input vectors specific to a certain input element.<br> \n",
    "In the first step of the self-attention mechanism with trainable weight matrices, we\n",
    "compute query (q), key (k), and value (v) vectors for input elements x<br>\n",
    "The query vector q\n",
    "(2)\n",
    "is obtained\n",
    "via matrix multiplication between the input x\n",
    "(2) and the weight matrix Wq.\n",
    "<br>Similarly, we obtain\n",
    "the key and value vectors via matrix multiplication involving the weight matrices Wk and Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd333c13-d6ef-4d76-b98c-927c3ddbbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Your journey starts with one step'\n",
    "\n",
    "# sample embeddings of input text\n",
    "inputs_emb = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # Your (x^1)\n",
    "[0.55, 0.87, 0.66], # journey (x^2)\n",
    "[0.57, 0.85, 0.64], # starts (x^3)\n",
    "[0.22, 0.58, 0.33], # with (x^4)\n",
    "[0.77, 0.25, 0.10], # one (x^5)\n",
    "[0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd7c8a-d2c3-4920-af00-82ddca0fa2f9",
   "metadata": {},
   "source": [
    "### Step 1: initialize the query, key and value weight vectors\n",
    "<br>Weight parameters are the fundamental, learned coefficients that define the network's connections, while attention weights are dynamic, context-specific values.\n",
    "Even though our temporary goal is to only compute the one context vector, z (2) , we still require the key and value vectors for all input elements as they are involved in computing the attention weights with respect to the query q (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0b36e-2e7c-45b1-b826-9d3e086f2474",
   "metadata": {},
   "source": [
    "A \"query\" is analogous to a search query in a database. It represents the\n",
    "current item (e.g., a word or token in a sentence) the model focuses on or\n",
    "tries to understand. The query is used to probe the other parts of the input\n",
    "sequence to determine how much attention to pay to them.\n",
    "<br>The \"key\" is like a database key used for indexing and searching. In the\n",
    "attention mechanism, each item in the input sequence (e.g., each word in a\n",
    "sentence) has an associated key. These keys are used to match with the query.\n",
    "<br>The \"value\" in this context is similar to the value in a key-value pair in a\n",
    "database. It represents the actual content or representation of the input items.\n",
    "Once the model determines which keys (and thus which parts of the input)\n",
    "are most relevant to the query (the current focus item), it retrieves the\n",
    "corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4d05e4-70bb-43d1-971e-a16b6787b4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8585, 0.5272])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2345)\n",
    "x_2=inputs_emb[1]  # querry input\n",
    "d_in = inputs_emb.shape[1]\n",
    "d_out=2\n",
    "\n",
    "\n",
    "\n",
    "# Step1: manually setting querry, key and value weights matrices\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out),requires_grad=False) # although these are trainable parameters, for convinience we have set the requires_grad=False\n",
    "W_key =  torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value=torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "\n",
    "query_2 = x_2@W_query\n",
    "query_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe3abb-91fe-422b-a00b-6b0f7a060574",
   "metadata": {},
   "source": [
    "### Step2: Compute the attention scores of input tokens w.r.t query\n",
    "The attention score computation is a dot-product between  the query and\n",
    "key obtained by transforming the inputs via the respective weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "255f3dfa-1f45-410e-b61d-5e5fce59541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "keys = inputs_emb@W_key\n",
    "attn_score21 = query_2@keys[0] # attention score for input 1 w.r.t query\n",
    "attn_score22 = query_2@keys[0] # attention score of input 2 w.r.t qury. Here input2 is query itself\n",
    "# and so on....\n",
    "\n",
    "# all attention score with respect to query 2\n",
    "attn_scores_2 = query_2@keys.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690cdbe-461d-48fe-b6a8-40c33f507e8b",
   "metadata": {},
   "source": [
    "### Step3: Compute the attention weights from attention scores\n",
    "First scale the attention scores by deviding with square root of embeded dimension of keys and then normalize through softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9d75880-8a78-4655-9a62-e294dfe05d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weights:  tensor([0.1270, 0.2193, 0.2178, 0.1390, 0.1422, 0.1546])\n",
      "\n",
      "sum of weights:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_scores_2_scalled = attn_scores_2/np.sqrt(d_k)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2_scalled, dim=-1)\n",
    "print('attention weights: ', attn_weights_2)\n",
    "print('\\nsum of weights: ', attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8251999-e6e0-4ec5-a852-9b011b2660ed",
   "metadata": {},
   "source": [
    "### Step4: Context Vector\n",
    "Obtain the context vector by multiplying each value vector with its respective attention weight and then sum up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e184d0e-12cd-4695-b427-aea49a5f21be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4204, 0.7237],\n",
       "        [0.8305, 1.0672],\n",
       "        [0.8125, 1.0579],\n",
       "        [0.5063, 0.5819],\n",
       "        [0.2597, 0.5928],\n",
       "        [0.7082, 0.7108]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values=inputs_emb@W_value\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebc2c80e-d175-4558-82f6-5443cc2d7ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6293, 0.8315])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vect_2 = attn_weights_2@values\n",
    "context_vect_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e6c8b-8abb-4c8b-bf9a-2158ff9811b8",
   "metadata": {},
   "source": [
    "### Implementing a compact self-attention Python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f880e90-8bf9-4e4b-b711-8c932f408a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        # weights for query, key and values\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        # x= input embedding matrix\n",
    "        # query matri\n",
    "        query = x@self.W_query\n",
    "        # key matrix\n",
    "        key = x@self.W_key\n",
    "        # Value matrix\n",
    "        value = x@self.W_value\n",
    "        # attention scores (keys w.r.t queries)\n",
    "        all_attention_scores=q@k.T\n",
    "        all_attention_scores_scalled=all_attention_scores/np.sqrt(k.shape[-1])\n",
    "        all_attention_weights=torch.softmax(all_attention_scores_scalled, dim=-1)\n",
    "        context_vectors = all_attention_weights@values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c627767c-2c43-4bc1-9e7c-c504129168d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6204, 0.8173],\n",
       "        [0.6491, 0.8449],\n",
       "        [0.6486, 0.8444],\n",
       "        [0.6251, 0.8217],\n",
       "        [0.6244, 0.8211],\n",
       "        [0.6319, 0.8281]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(345)\n",
    "self_attn = SelfAttention_v1(3,2)\n",
    "context_vectors=  self_attn(inputs_emb)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75bfd3ce-e1a0-4434-aaad-bb8c2d6c9cf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'crewai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'crewai'"
     ]
    }
   ],
   "source": [
    "import crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaebe1-2405-475d-9fbe-84b27d8c2c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
